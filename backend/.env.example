# AegisProxy Environment Configuration
# Copy this file to .env and configure your settings

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# OpenAI API Key (required for OpenAI provider)
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI Base URL (optional, for Azure OpenAI or custom endpoints)
# OPENAI_BASE_URL=https://api.openai.com/v1

# Google Gemini API Key (optional, for Gemini provider)
# GEMINI_API_KEY=your-gemini-api-key-here

# Default LLM provider: openai, gemini
AEGIS_DEFAULT_PROVIDER=openai

# =============================================================================
# Server Configuration
# =============================================================================

# Host and port for the AegisProxy server
AEGIS_HOST=0.0.0.0
AEGIS_PORT=8080

# Enable debug mode (more verbose logging)
AEGIS_DEBUG=false

# =============================================================================
# Security Settings
# =============================================================================

# Injection detection threshold (0.0-1.0, higher = more strict)
AEGIS_INJECTION_THRESHOLD=0.7

# Action when injection detected: block, warn
AEGIS_INJECTION_ACTION=block

# PII detection confidence threshold (0.0-1.0)
AEGIS_PII_THRESHOLD=0.7

# Redaction mode: placeholder, type_only, mask, hash
AEGIS_REDACTION_MODE=placeholder

# =============================================================================
# Logging & Telemetry
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR
AEGIS_LOG_LEVEL=INFO

# Enable Prometheus metrics endpoint
AEGIS_METRICS_ENABLED=true
AEGIS_METRICS_PORT=9090

# Log format: json, console
AEGIS_LOG_FORMAT=json
